{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from pathlib import Path\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "CUSTOMIZATIONSTXT_PATH = r\"..\\data\\processed\\customizations_doc.txt\"\n",
    "FAQTXT_PATH = r\"..\\data\\processed\\faq_doc.txt\"\n",
    "UPDATED_FAQTXT_PATH = r\"..\\data\\processed\\updated_faq_doc.txt\"\n",
    "CHROMADB_PATH = r\"..\\chromadb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(filepath: str) -> str:\n",
    "    raw_text = docx2txt.process(filepath)\n",
    "    lines = []\n",
    "    for line in raw_text.split(\"\\n\"):\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        lines.append(line.strip())\n",
    "    processed_text = \"\\n\".join(lines)\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def create_updated_faq(\n",
    "        faq_filepath: str,\n",
    "        customizations_filepath: str,\n",
    "        updated_faq_filepath: str = r\".\\updated_faq_doc.txt\"\n",
    "        ) -> None:\n",
    "    with open(faq_filepath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        faq_data = f.read()\n",
    "\n",
    "    new_faq_entries = generate_customizations_faq_entry(customizations_filepath)\n",
    "\n",
    "    updated_faq_data = faq_data + \"\\n\" + \"\\n\".join(new_faq_entries)\n",
    "    \n",
    "    with open(updated_faq_filepath, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        f.write(updated_faq_data)\n",
    "\n",
    "\n",
    "def parse_faq_file(filepath: str) -> list[str]:\n",
    "    with open(filepath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        faq_data = f.read()\n",
    "\n",
    "    pattern = re.compile(r'Q:(.*)\\nA:(.*)')\n",
    "    parsed_faq_data = re.findall(pattern , faq_data)\n",
    "\n",
    "    refactored_parsed_faq_data = [f\"question:{question.strip().lower()}\\n answer:{answer.strip().lower()}\"\n",
    "                                  for question, answer in parsed_faq_data]\n",
    "    return refactored_parsed_faq_data\n",
    "\n",
    "\n",
    "def parse_customizations_file(filepath: str) -> dict[str, list[str]]:\n",
    "    with open(filepath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        text = f.read().lower()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'^(?P<category>[\\w\\s]+):\\s*\\n(?P<values>(?:\\s*-\\s*.*(?:\\n|$))+)', \n",
    "        re.MULTILINE\n",
    "    )\n",
    "\n",
    "    customizations = {}\n",
    "    for match in pattern.finditer(text):\n",
    "        category = match.group('category').strip()\n",
    "        values_block = match.group('values')\n",
    "\n",
    "        values = re.findall(r'-\\s*(.*)', values_block)\n",
    "        \n",
    "        if category.lower() == \"sizes\":\n",
    "            new_values = []\n",
    "            for v in values:\n",
    "                if ',' in v:\n",
    "                    new_values.extend([x.strip() for x in v.split(\",\")])\n",
    "                else:\n",
    "                    new_values.append(v)\n",
    "            values = new_values\n",
    "        customizations[category] = values\n",
    "    return customizations\n",
    "\n",
    "\n",
    "def generate_customizations_faq_entry(filepath: str) -> list[str]:\n",
    "    customization_options = parse_customizations_file(filepath)\n",
    "\n",
    "    new_faq_entries = []\n",
    "    \n",
    "    # Create an entry about available customizations\n",
    "    question = f\"Q: What are the available customization options of t-shirts do you have?\"\n",
    "    answer = f\"A: We have \" + \", \".join(attribute for attribute, _ in customization_options.items())\n",
    "\n",
    "    new_faq_entry = question + \"\\n\" + answer + \"\\n\"\n",
    "    new_faq_entries.append(new_faq_entry)\n",
    "\n",
    "    # Create entries about specific customizations\n",
    "    for attribute, values in customization_options.items():\n",
    "        question = f\"Q: What are the available {attribute} of t-shirts do you have?\"\n",
    "        answer = f\"A: We have \" + \", \".join(values)\n",
    "\n",
    "        new_faq_entry = question + \"\\n\" + answer + \"\\n\"\n",
    "        new_faq_entries.append(new_faq_entry)\n",
    "    return new_faq_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the initial files to TXT format\n",
    "- We assume, that initial customization and FAQ files are placed into the data\\raw directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide paths to the initial files\n",
    "CUSTOMIZATIONSDOCX_PATH = Path(r\"..\\data\\raw\\Anadea homework  - Tee Customizer Shirts.docx\")\n",
    "FAQDOCX_PATH = Path(r\"..\\data\\raw\\Anadea homework  -Tee Customizer FAQ.docx\")\n",
    "\n",
    "assert os.path.exists(CUSTOMIZATIONSDOCX_PATH), r\"Initial customization file is not present in the 'data\\raw' dir.\"\n",
    "assert os.path.exists(FAQDOCX_PATH), r\"Initial FAQ file is not present in the 'data\\raw' dir.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map old filesnames to the new ones\n",
    "filepath_mapping = {CUSTOMIZATIONSDOCX_PATH: CUSTOMIZATIONSTXT_PATH,\n",
    "                    FAQDOCX_PATH: FAQTXT_PATH}\n",
    "\n",
    "# Check if there is a folder for processed data\n",
    "if not os.path.exists(r\"..\\data\\processed\"):\n",
    "    os.mkdir(r\"..\\data\\processed\")\n",
    "\n",
    "# Convert files to .docx files to .txt\n",
    "for src_path, new_path in filepath_mapping.items():\n",
    "    content = read_docx(src_path)\n",
    "    with open(new_path, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update FAQ file\n",
    "- We will update FAQ file with the information from the customizations document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new updated FAQ file\n",
    "create_updated_faq(r\"..\\data\\processed\\faq_doc.txt\",\n",
    "                   r\"..\\data\\processed\\customizations_doc.txt\",\n",
    "                   r\"..\\data\\processed\\updated_faq_doc.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector database\n",
    "- We will use ChromaDB as a vector database\n",
    "- We will populate vdb with the information from the FAQ doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract quaestions and answers from the FAQ doc\n",
    "faq_data = parse_faq_file(UPDATED_FAQTXT_PATH)\n",
    "\n",
    "\n",
    "metadata={\"source\": \"Tee Customizer FAQ\"}\n",
    "docs = [Document(text, metadata=metadata) for text in faq_data]\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"BAAI/llm-embedder\")\n",
    "vector_store = Chroma.from_documents(documents=docs,\n",
    "                                     embedding=embedding_function,\n",
    "                                     persist_directory=CHROMADB_PATH,\n",
    "                                     collection_name=\"faq_collection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
